

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quick Start Guide &mdash; PyKEEN Negative Sampling Extension 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="PyKEEN Extension" href="extension.html" />
    <link rel="prev" title="PyKEEN Negative Sampling Extension documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            PyKEEN Negative Sampling Extension
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Start Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installing-requirements">Installing requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#import-the-extension-and-setting-paths">Import the extension and setting paths</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-a-dataset">Loading a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-static-negative-samplers">Using Static Negative Samplers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-dynamic-negative-samplers">Using Dynamic Negative Samplers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-negative-samplers-in-pykeen-pipelines">Using Negative Samplers in PyKEEN Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#writing-you-own-custom-negative-samplers">Writing you own custom Negative Samplers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#integration-of-random-negatives">Integration of random negatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generating-negative-sampler-statistics">Generating Negative Sampler Statistics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extension.html">PyKEEN Extension</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyKEEN Negative Sampling Extension</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Quick Start Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quick.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quick-start-guide">
<h1>Quick Start Guide<a class="headerlink" href="#quick-start-guide" title="Link to this heading"></a></h1>
<p>This tutorial will guide you in a quickstarting you in using the new negative samplers in a PyKEEN pipeline. A Jupyter Notebook Version of this resouce is available in the repository main folder. This tutorial is designed as a progressive guide to help you understand and use the core features of the library. Each section builds upon the previous ones, so we recommend following them in order.</p>
<section id="installing-requirements">
<h2>Installing requirements<a class="headerlink" href="#installing-requirements" title="Link to this heading"></a></h2>
<p>Please be sure to have the following requirements installed in your system</p>
<ul class="simple">
<li><p>Python 3.x</p></li>
<li><p>pip</p></li>
</ul>
<p>Regarding libraries, the extension is built entirely around PyKEEN, and does not need other external libraries.
In case an exact replica of the installed packed and version is needed, you can use the provided requirements file, installable with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</section>
<section id="import-the-extension-and-setting-paths">
<h2>Import the extension and setting paths<a class="headerlink" href="#import-the-extension-and-setting-paths" title="Link to this heading"></a></h2>
<p>Let’s import all the required libraries to use our extension within the PyKEEN ecosystem, here we import all the samplers, filterer and dataset classes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pykeen</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pykeen.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pykeen.sampling</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BasicNegativeSampler</span><span class="p">,</span>
    <span class="n">BernoulliNegativeSampler</span><span class="p">,</span>
    <span class="n">negative_sampler_resolver</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pykeen.sampling.filtering</span><span class="w"> </span><span class="kn">import</span> <span class="n">filterer_resolver</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pykeen.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">SLCWATrainingLoop</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">extension.dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">OnMemoryDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">extension.filtering</span><span class="w"> </span><span class="kn">import</span> <span class="n">NullPythonSetFilterer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">extension.sampling</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CorruptNegativeSampler</span><span class="p">,</span>
    <span class="n">NearestNeighbourNegativeSampler</span><span class="p">,</span>
    <span class="n">NearMissNegativeSampler</span><span class="p">,</span>
    <span class="n">RelationalNegativeSampler</span><span class="p">,</span>
    <span class="n">SubSetNegativeSampler</span><span class="p">,</span>
    <span class="n">TypedNegativeSampler</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">extension.constants</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">const</span>
</pre></div>
</div>
</section>
<section id="loading-a-dataset">
<h2>Loading a Dataset<a class="headerlink" href="#loading-a-dataset" title="Link to this heading"></a></h2>
<p>A dataset can be loaded referencing the main folder where it is located. Using our custom dataloader the fixed entity and id mappings will be loaded, and we can choose wheter to load or not additional metadata. The data loading process handles the mapping of names to ids in the loaded metadata files. We choose YAGO4-20 in this tutorial since it is provided with additional metadata.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">OnMemoryDataset</span><span class="p">(</span>
    <span class="n">data_path</span><span class="o">=</span><span class="s2">&quot;/&lt;custom_path_to_dataset_folder&gt;/YAGO4-20&quot;</span><span class="p">,</span> <span class="n">load_domain_range</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">load_entity_classes</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The additional metadata are stored in two data properties:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">entity_id_to_classes</span>  <span class="c1"># Dictionary with mapping from entity ID to list of class names</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">relation_id_to_domain_range</span> <span class="c1"># Dictionary with mappings from entity ID to domain and range class</span>
</pre></div>
</div>
</section>
<section id="using-static-negative-samplers">
<h2>Using Static Negative Samplers<a class="headerlink" href="#using-static-negative-samplers" title="Link to this heading"></a></h2>
<p>In this tutorial we will use the Typed negative sampler, levaraging the additional metadata loaded from YAGO4-20, you can instantiate the negative sampler using the standard PyKEEN negative sampler interface, adding the additional arguments needed for the specific sampler, in this case we will provide the entity to classes mapping and the relation to domain and range mapping. In order to leverage fully the functionalities of this sampler, we also use the <code class="docutils literal notranslate"><span class="pre">NullPythonSetFilterer</span></code>, instantiate like any other filterer in the PyKEEN ecosystem:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">filterer</span> <span class="o">=</span> <span class="n">NullPythonSetFilterer</span><span class="p">(</span><span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">TypedNegativeSampler</span><span class="p">(</span>
        <span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">,</span>
        <span class="n">filtered</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">filterer</span><span class="o">=</span><span class="n">filterer</span><span class="p">,</span>
        <span class="n">num_negs_per_pos</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">entity_classes_dict</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">entity_id_to_classes</span><span class="p">,</span>
        <span class="n">relation_domain_range_dict</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">relation_id_to_domain_range</span><span class="p">,</span>
        <span class="n">integrate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Then after instantiation the sampler can be used like any other PyKEEN negative sampler:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-dynamic-negative-samplers">
<h2>Using Dynamic Negative Samplers<a class="headerlink" href="#using-dynamic-negative-samplers" title="Link to this heading"></a></h2>
<p>Dynamic negative samplers require some addiotional configuration before hand, first, lets train a model like <code class="docutils literal notranslate"><span class="pre">TransE</span></code> on our chosen dataset, this will be used as the auxiliary sampling model in the corruption procedure.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pykeen</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">TransE</span><span class="p">(</span><span class="n">triples_factory</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">loop</span> <span class="o">=</span> <span class="n">SLCWATrainingLoop</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">triples_factory</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span>
<span class="p">)</span>

<span class="n">loop</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">triples_factory</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, lets define the custom function used to get the predicted entity vector representation, this function expect to receive the model, a batch, and the targets for corruption (list of head or tail in ID form)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sampling_model_prediction</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">hrt_batch</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="n">hrt_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">model</span><span class="o">.</span><span class="n">entity_representations</span><span class="p">[</span><span class="mi">0</span><span class="p">]()</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
        <span class="n">device</span><span class="o">=</span><span class="n">hrt_batch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">out</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">entity_representations</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
        <span class="n">hrt_batch</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">relation_representations</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hrt_batch</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">out</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">entity_representations</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span>
        <span class="n">hrt_batch</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">relation_representations</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">hrt_batch</span><span class="p">[</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>Now we can instantiate our dynamic negative sampler providing the additional pretrained model and prediction function. Since the adversarial sampler uses a nearest neighbour algorithm internally, we can also define the K parameter with the <code class="docutils literal notranslate"><span class="pre">num_query_results</span></code> argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">NearMissNegativeSampler</span><span class="p">(</span>
    <span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">,</span>
    <span class="n">prediction_function</span><span class="o">=</span><span class="n">sampling_model_prediction</span><span class="p">,</span>
    <span class="n">sampling_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">num_negs_per_pos</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">num_query_results</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">filtered</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">filterer</span><span class="o">=</span><span class="n">filterer</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then after instantiation the sampler can be used like any other PyKEEN negative sampler:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-negative-samplers-in-pykeen-pipelines">
<h2>Using Negative Samplers in PyKEEN Pipelines<a class="headerlink" href="#using-negative-samplers-in-pykeen-pipelines" title="Link to this heading"></a></h2>
<p>Using our custom samplers in PyKEEN pipelines is even easier, we just need to provied them as input to the pipeline, or even easier, register them in the PyKEEN namespace, allowing to refer to them only using their name, like other available negative samplers in the library.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">negative_sampler_resolver</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">element</span><span class="o">=</span><span class="n">CorruptNegativeSampler</span><span class="p">)</span>
<span class="n">filterer_resolver</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">element</span><span class="o">=</span><span class="n">NullPythonSetFilterer</span><span class="p">)</span>

<span class="n">pipeline_result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;Nations&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;TransE&quot;</span><span class="p">,</span>
    <span class="n">negative_sampler</span><span class="o">=</span><span class="s2">&quot;corrupt&quot;</span><span class="p">,</span>
    <span class="n">negative_sampler_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">filtered</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">filterer</span><span class="o">=</span><span class="s2">&quot;nullpythonset&quot;</span><span class="p">),</span>
    <span class="n">training_loop</span><span class="o">=</span><span class="s2">&quot;sLCWA&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="writing-you-own-custom-negative-samplers">
<h2>Writing you own custom Negative Samplers<a class="headerlink" href="#writing-you-own-custom-negative-samplers" title="Link to this heading"></a></h2>
<p>One core contribution in our proposed extension is abstraction on negative sampling computation, providing an abstract class for static samplers that hides all the need computation, allowing developers to define their own samplers implementing only the core logic of the negative sampling process. In this tutorial we will show a new simple negative sampler implemented using our proposed abstaction.</p>
<p>This sampler, named <code class="docutils literal notranslate"><span class="pre">TutorialSampler</span></code> defined a negative pool for a triple, as the least occuring entities for its relation as head (if corrupting the head entity) or tail (if corrupting the tail entity). So the negative pool for each triple will depend solely on its relation. Let’s see how to implement this strategy:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TutorialSampler</span><span class="p">(</span><span class="n">SubSetNegativeSampler</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># We define this variable before super, to it can be available in the subset generation</span>
        <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;top_k&quot;</span><span class="p">,</span> <span class="n">top_k</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Precompute the entity set for head and tail for each relation</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_subset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mapped_triples</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">subset</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_relations</span><span class="p">):</span>

            <span class="n">subset</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

            <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="p">[</span><span class="n">const</span><span class="o">.</span><span class="n">HEAD</span><span class="p">,</span> <span class="n">const</span><span class="o">.</span><span class="n">TAIL</span><span class="p">]:</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">[:,</span> <span class="n">const</span><span class="o">.</span><span class="n">REL</span><span class="p">]</span> <span class="o">==</span> <span class="n">r</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span>
                    <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">ordered_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">]][</span>
                    <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span>
                <span class="p">]</span>

                <span class="n">subset</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">ordered_data</span>

        <span class="k">return</span> <span class="n">subset</span>

    <span class="c1"># Now lets define the negative pool for each triple</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">strategy_negative_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">subset</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="n">const</span><span class="o">.</span><span class="n">TARGET_TO_INDEX</span><span class="p">[</span><span class="n">target</span><span class="p">]]</span>
</pre></div>
</div>
<p>As you can see implementing a new negative sampler is extremely easy, requiring only the core logic for the subset, and the core logic for extracting the negative pool. Our abstraction hides all the computation on batching, interleaving for multiple negative per positive, filtering, and random selection from the negative pool. If necessary, a developer could also override the <code class="docutils literal notranslate"><span class="pre">choose_from_pool</span></code> function, providing specific functionality on how to sample negative form the negative pool.</p>
<p>After this this new negative sampler can be used like any other one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">TutorialSampler</span><span class="p">(</span>
    <span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">num_negs_per_pos</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="integration-of-random-negatives">
<h2>Integration of random negatives<a class="headerlink" href="#integration-of-random-negatives" title="Link to this heading"></a></h2>
<p>Using the previous example as negative sampler, given, for example, the top 50 least occuring entities for each relation, each negative pool will have exaclty 50 different entities. If we set a number of <code class="docutils literal notranslate"><span class="pre">num_negs_per_pos</span></code> (number of negative triple to generate for each positive triple) higher than this number, like 100, we will have a lot of dupliate negative in our negative pools. This situation, in general, arises when the negative pool strategy is not able to produce enough negatives, in this case, we can set the <code class="docutils literal notranslate"><span class="pre">integrate</span></code> argument to <code class="docutils literal notranslate"><span class="pre">True</span></code>, and our implementation will automatically detect when a specific negative pool doesn’t reach the desired number of negatives and supplement it with randomly sampled entities, this can be done as simple as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">TutorialSampler</span><span class="p">(</span>
    <span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">num_negs_per_pos</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">integrate</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="generating-negative-sampler-statistics">
<h2>Generating Negative Sampler Statistics<a class="headerlink" href="#generating-negative-sampler-statistics" title="Link to this heading"></a></h2>
<p>Additionaly you can compute the dataset statistics directly using our provided functions, this can take some time, since this computation as to be computed for each <code class="docutils literal notranslate"><span class="pre">&lt;h,r,*&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;*,r,t&gt;</span></code> combination, in our notebook tutorial we test it on a subset of the training triples, in order to speed up the computation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">TutorialSampler</span><span class="p">(</span>
    <span class="n">mapped_triples</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_negs_per_pos</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>

<span class="n">sampler</span><span class="o">.</span><span class="n">average_pool_size</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">mapped_triples</span><span class="p">)</span>
</pre></div>
</div>
<p>The function produces the average number of entities in each negative pool (checking if there are false negative), and then in order, the number of triples that have less than 0, 2, 10, 40, 100 entities in their negative pool.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="PyKEEN Negative Sampling Extension documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="extension.html" class="btn btn-neutral float-right" title="PyKEEN Extension" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Ivan Diliso.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>