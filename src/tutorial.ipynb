{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3936bbe",
   "metadata": {},
   "source": [
    "# PyKEEN Negative Sampling Extension: A introductory Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c7e9d",
   "metadata": {},
   "source": [
    "This tutorial will guide you with the basic usage of the new negative samplers classes. Remember to unzip the provided dataset file the the data/ folder, in order to assure the correct functionalities of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efec0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navis/.pyenv/versions/pykeen-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pykeen\n",
    "from pykeen.sampling import BasicNegativeSampler, BernoulliNegativeSampler\n",
    "\n",
    "from extension.sampling import (CorruptNegativeSampler,\n",
    "                                NearestNeighbourNegativeSampler,\n",
    "                                NearMissNegativeSampler,\n",
    "                                RelationalNegativeSampler,\n",
    "                                TypedNegativeSampler)\n",
    "\n",
    "from extension.filtering import NullPythonSetFilterer\n",
    "from extension.dataset import OnMemoryDataset\n",
    "from pathlib import Path\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb0658",
   "metadata": {},
   "source": [
    "This should automatically get the correct data path given the tutorial provided location, if needed, modify this path with your custom \"data\" folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8857b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/navis/dev/refactor-negative-sampler/data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path().cwd().parent / \"data\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b02245",
   "metadata": {},
   "source": [
    "## Loading the provided datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97aa95",
   "metadata": {},
   "source": [
    "Let's load the YAGO4-20 dataset, with the additional provided metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20081d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OnMemoryDataset(\n",
    "    data_path = data_path / \"YAGO4-20\",\n",
    "    load_domain_range = True,\n",
    "    load_entity_classes = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f625999",
   "metadata": {},
   "source": [
    "Now you can use all the basic functionalities of the standard pykeen dataset, with added loaded data of domain and range proprieties, and entity class membership, lets see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89adfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Entities 96910\n",
      "Num Relations 70\n",
      "Relation Mapping {'about': 0, 'actor': 1, 'affiliation': 2, 'alumniOf': 3, 'author': 4, 'award': 5, 'bioChemInteraction': 6, 'birthPlace': 7, 'brand': 8, 'byArtist': 9, 'character': 10, 'children': 11, 'citation': 12, 'competitor': 13, 'composer': 14, 'containedInPlace': 15, 'containsPlace': 16, 'contentLocation': 17, 'contributor': 18, 'copyrightHolder': 19, 'countryOfOrigin': 20, 'creator': 21, 'deathPlace': 22, 'director': 23, 'editor': 24, 'exampleOfWork': 25, 'familyName': 26, 'founder': 27, 'foundingLocation': 28, 'gender': 29, 'genre': 30, 'givenName': 31, 'hasMolecularFunction': 32, 'hasOccupation': 33, 'hasPart': 34, 'homeLocation': 35, 'honorificPrefix': 36, 'inLanguage': 37, 'isBasedOn': 38, 'isInvolvedInBiologicalProcess': 39, 'isLocatedInSubcellularLocation': 40, 'isPartOf': 41, 'knowsLanguage': 42, 'license': 43, 'location': 44, 'locationCreated': 45, 'material': 46, 'memberOf': 47, 'musicBy': 48, 'nationality': 49, 'parent': 50, 'parentOrganization': 51, 'parentTaxon': 52, 'partOfSeason': 53, 'partOfSeries': 54, 'producer': 55, 'productionCompany': 56, 'publisher': 57, 'relevantSpecialty': 58, 'signOrSymptom': 59, 'sponsor': 60, 'sport': 61, 'spouse': 62, 'subEvent': 63, 'subOrganization': 64, 'superEvent': 65, 'taxonRank': 66, 'translator': 67, 'workExample': 68, 'worksFor': 69}\n",
      "Domain and Range of 'character': {'domain': 'CreativeWork', 'range': 'Person'}\n",
      "Entity Classes of '10_Rillington_Place': ['Movie']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Entities {dataset.num_entities}\")\n",
    "print(f\"Num Relations {dataset.num_relations}\")\n",
    "print(f\"Relation Mapping {dataset.relation_to_id}\")\n",
    "\n",
    "relation_id = 10\n",
    "entity_id = 50\n",
    "\n",
    "id_to_entity = {v:k for k,v in dataset.entity_to_id.items()}\n",
    "id_to_relation = {v:k for k,v in dataset.relation_to_id.items()}\n",
    "\n",
    "print(f\"Domain and Range of '{id_to_relation[relation_id]}': {dataset.relation_id_to_domain_range[relation_id]}\")\n",
    "print(f\"Entity Classes of '{id_to_entity[entity_id]}': {dataset.entity_id_to_classes[entity_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399b8e0",
   "metadata": {},
   "source": [
    "## Using the static negative samplers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45daf0b7",
   "metadata": {},
   "source": [
    "Lets instantiate some static negative samplers, the corrupt, and typed, that used the additional metadata, we just use the pykeen inferface and provide the additional required metadata loaded with the dataset. In this case we set the integration of random negatives to false, in oder to showcase the real negatives generated with these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51811e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterer = NullPythonSetFilterer(\n",
    "    mapped_triples=dataset.training.mapped_triples\n",
    ")\n",
    "\n",
    "samplers = {\n",
    "    \"Corrupt\" : CorruptNegativeSampler(\n",
    "        mapped_triples = dataset.training.mapped_triples,\n",
    "        filtered = True,\n",
    "        filterer = filterer,\n",
    "        num_negs_per_pos = 5,\n",
    "        integrate = False\n",
    "    ),\n",
    "    \"Typed\" : TypedNegativeSampler(\n",
    "        mapped_triples = dataset.training.mapped_triples,\n",
    "        filtered = True,\n",
    "        filterer = filterer,\n",
    "        num_negs_per_pos = 5,\n",
    "        entity_classes_dict=dataset.entity_id_to_classes,\n",
    "        relation_domain_range_dict=dataset.relation_id_to_domain_range,\n",
    "        integrate = False\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824dc21",
   "metadata": {},
   "source": [
    "Now lets use the sampler to produce the negative for the first 2 triples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf7e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sampler: Corrupt\n",
      "(tensor([[[    0,     1, 68452],\n",
      "         [    0,     1,  5994],\n",
      "         [84822,     1,  5226],\n",
      "         [84698,     1,  5226],\n",
      "         [    0,     1,  9090]],\n",
      "\n",
      "        [[    0,     1, 41384],\n",
      "         [    0,     1, 64844],\n",
      "         [ 7829,     1, 19014],\n",
      "         [    0,     1, 57403],\n",
      "         [85227,     1, 19014]]]), tensor([[True, True, True, True, True],\n",
      "        [True, True, True, True, True]]))\n",
      "\n",
      "Negative Sampler: Typed\n",
      "(tensor([[[    0,     1, 27722],\n",
      "         [    0,     1, 42456],\n",
      "         [    0,     1, 79084],\n",
      "         [86399,     1,  5226],\n",
      "         [ 2614,     1,  5226]],\n",
      "\n",
      "        [[    0,     1, 27722],\n",
      "         [87083,     1, 19014],\n",
      "         [84942,     1, 19014],\n",
      "         [    0,     1, 79084],\n",
      "         [    0,     1, 60725]]]), tensor([[True, True, True, True, True],\n",
      "        [True, True, True, True, True]]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, sampler in samplers.items():\n",
    "    print(f\"Negative Sampler: {name}\")\n",
    "    print(samplers[name].sample(dataset.training.mapped_triples[:2]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b501b6c",
   "metadata": {},
   "source": [
    "## Using dynamic negative samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc2ba6",
   "metadata": {},
   "source": [
    "In oder to use the dynamic negative samplers, we will need to first pretrain a model, for this purpose, lets train Transe on YAGO for 2 epochs, just for the sake of the tutorial, using a random sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4583b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. This may lead to non-reproducible results.\n",
      "Training epochs on cpu: 100%|██████████| 2/2 [00:32<00:00, 16.04s/epoch, loss=0.804, prev_loss=0.984]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9840400149988215, 0.804481829570262]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pykeen.models\n",
    "\n",
    "\n",
    "model = pykeen.models.TransE(\n",
    "    triples_factory = dataset.training,\n",
    "    embedding_dim=10\n",
    ")\n",
    "\n",
    "loop = SLCWATrainingLoop(\n",
    "    model= model,\n",
    "    triples_factory = dataset.training,\n",
    "    optimizer=\"Adam\"\n",
    ")\n",
    "\n",
    "loop.train(\n",
    "    triples_factory=dataset.training,\n",
    "    num_epochs=2,\n",
    "    batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e932f",
   "metadata": {},
   "source": [
    "Now lets define the custom function used for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8898f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_model_prediction(model, hrt_batch, targets):\n",
    "    out = torch.zeros(\n",
    "        (hrt_batch.size(0), model.entity_representations[0]().size(1)),\n",
    "        device=hrt_batch.device,\n",
    "    )\n",
    "    out[targets == 0] = model.entity_representations[0](\n",
    "        hrt_batch[targets == 0, 2]\n",
    "    ) - model.relation_representations[0](hrt_batch[targets == 0, 1])\n",
    "    out[targets == 2] = model.entity_representations[0](\n",
    "        hrt_batch[targets == 2, 0]\n",
    "    ) + model.relation_representations[0](hrt_batch[targets == 2, 1])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1afe5",
   "metadata": {},
   "source": [
    "And not we can instantiate the Adversarial negative sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7778268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NearMissNegativeSampler(\n",
    "    mapped_triples = dataset.training.mapped_triples,\n",
    "    prediction_function=sampling_model_prediction,\n",
    "    sampling_model=model,\n",
    "    num_query_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380497b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92mDONE\u001b[0m ] [NS NearMissNegativeSampler] Calculating HEAD prediction with TransE pretrained model in \u001b[96m0000.0021\u001b[0ms\n",
      "[\u001b[92mDONE\u001b[0m ] [NS NearMissNegativeSampler] Calculating TAIL prediction with TransE pretrained model in \u001b[96m0000.0005\u001b[0ms\n",
      "[\u001b[92mDONE\u001b[0m ] [NS NearMissNegativeSampler] Querying KDTREE for HEAD predictions in \u001b[96m0000.0025\u001b[0ms\n",
      "[\u001b[92mDONE\u001b[0m ] [NS NearMissNegativeSampler] Querying KDTREE for TAIL predictions in \u001b[96m0000.0024\u001b[0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5226",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/pykeen-venv/lib/python3.12/site-packages/pykeen/sampling/negative_sampler.py:88\u001b[39m, in \u001b[36mNegativeSampler.sample\u001b[39m\u001b[34m(self, positive_batch)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate negative samples from the positive batch.\u001b[39;00m\n\u001b[32m     77\u001b[39m \n\u001b[32m     78\u001b[39m \u001b[33;03m:param positive_batch: shape: (batch_size, 3) The positive triples.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33;03m       valid.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# create unfiltered negative batch by corruption\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m negative_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorrupt_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filterer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m negative_batch, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/refactor-negative-sampler/src/extension/sampling.py:780\u001b[39m, in \u001b[36mNearMissNegativeSampler.corrupt_batch\u001b[39m\u001b[34m(self, positive_batch)\u001b[39m\n\u001b[32m    777\u001b[39m batch_end = batch_start + \u001b[38;5;28mself\u001b[39m.num_negs_per_pos\n\u001b[32m    779\u001b[39m triple_batch = negative_batch[batch_start:batch_end]\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m negative_heads, negative_tails = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchoose_from_pools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[38;5;66;03m# Head Corruption\u001b[39;00m\n\u001b[32m    785\u001b[39m triple_batch[: \u001b[38;5;28mself\u001b[39m.num_negs_per_pos // \u001b[32m2\u001b[39m][:, HEAD] = negative_heads\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/refactor-negative-sampler/src/extension/sampling.py:818\u001b[39m, in \u001b[36mNearMissNegativeSampler.choose_from_pools\u001b[39m\u001b[34m(self, triple, internal_id)\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchoose_from_pools\u001b[39m(\u001b[38;5;28mself\u001b[39m, triple, internal_id) -> torch.tensor:\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     head_negative_pool, tail_negative_pool = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy_negative_pool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHEAD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m[\u001b[49m\u001b[43mREL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTAIL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_id\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    822\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHDHDHDHDH\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    824\u001b[39m     num_head_negatives = \u001b[38;5;28mself\u001b[39m.num_negs_per_pos // \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/refactor-negative-sampler/src/extension/sampling.py:794\u001b[39m, in \u001b[36mNearMissNegativeSampler.strategy_negative_pool\u001b[39m\u001b[34m(self, h, r, t, internal_id)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstrategy_negative_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m, h, r, t, internal_id):\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     head_positive_pool, tail_positive_pool = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_positive_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m     head_negative_pool = \u001b[38;5;28mself\u001b[39m.subset[\u001b[33m\"\u001b[39m\u001b[33mhead_negative_pool\u001b[39m\u001b[33m\"\u001b[39m][internal_id]\n\u001b[32m    797\u001b[39m     tail_negative_pool = \u001b[38;5;28mself\u001b[39m.subset[\u001b[33m\"\u001b[39m\u001b[33mtail_negative_pool\u001b[39m\u001b[33m\"\u001b[39m][internal_id]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/refactor-negative-sampler/src/extension/sampling.py:213\u001b[39m, in \u001b[36mSubSetNegativeSampler.get_positive_pool\u001b[39m\u001b[34m(self, e, r, target)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize=\u001b[32m1024\u001b[39m, typed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_positive_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m, e: \u001b[38;5;28mint\u001b[39m, r: \u001b[38;5;28mint\u001b[39m, target: \u001b[38;5;28mstr\u001b[39m) -> torch.tensor:\n\u001b[32m    200\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns all the real negatives given an entity, a relation, and the taget for corruption.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    if target == \"head\" returns the full availabile negative entities for (*, rel, entity)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m    if target == \"tail\" returns the full availabile negative entities for (entity, rel, *)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m \u001b[33;03m        torch.tensor: Positive istances IDs\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     e_position = TARGET_TO_INDEX[\u001b[43mSWAP_TARGET\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[32m    215\u001b[39m     positive_pool = \u001b[38;5;28mself\u001b[39m.mapped_triples[\u001b[38;5;28mself\u001b[39m.mapped_triples[:, e_position] == e]\n\u001b[32m    216\u001b[39m     positive_pool = positive_pool[\n\u001b[32m    217\u001b[39m         positive_pool[:, REL] == r, TARGET_TO_INDEX[target]\n\u001b[32m    218\u001b[39m     ]\n",
      "\u001b[31mKeyError\u001b[39m: 5226"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial Negative Sampler\")\n",
    "print(sampler.sample(dataset.training.mapped_triples[:2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykeen-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
